{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjjuurang/CLIP/blob/main/StyleGAN3%2B%2B%2B%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMFvMqutlETj",
        "outputId": "691ae4c8-d183-4131-ff88-19421db1f95b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.4 MB/s eta 0:13:56tcmalloc: large alloc 1147494400 bytes == 0x39e0c000 @  0x7f67edd04615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.3 MB/s eta 0:12:52tcmalloc: large alloc 1434370048 bytes == 0x7e462000 @  0x7f67edd04615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:36tcmalloc: large alloc 1792966656 bytes == 0x3294000 @  0x7f67edd04615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.6 MB/s eta 0:03:39tcmalloc: large alloc 2241208320 bytes == 0x6e07c000 @  0x7f67edd04615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041315328 bytes == 0xf39de000 @  0x7f67edd031e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2551644160 bytes == 0x16d49e000 @  0x7f67edd04615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 8.7 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1+cu111) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1+cu111 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.1+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.1+cu111 torchvision-0.10.1+cu111\n",
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Total 207 (delta 0), reused 0 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (207/207), 4.17 MiB | 30.95 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Total 222 (delta 0), reused 0 (delta 0), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (222/222), 8.91 MiB | 31.58 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/CLIP\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.9.1+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.10.1+cu111)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.2.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Installing collected packages: ftfy, clip\n",
            "  Running setup.py develop for clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 10.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja, einops\n",
            "Successfully installed einops-0.4.1 ninja-1.10.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install --upgrade https://download.pytorch.org/whl/nightly/cu111/torch-1.11.0.dev20211012%2Bcu111-cp37-cp37m-linux_x86_64.whl https://download.pytorch.org/whl/nightly/cu111/torchvision-0.12.0.dev20211012%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "!git clone https://github.com/NVlabs/stylegan3\n",
        "!git clone https://github.com/openai/CLIP\n",
        "!pip install -e ./CLIP\n",
        "!pip install einops ninja\n",
        "\n",
        "import sys\n",
        "sys.path.append('./CLIP')\n",
        "sys.path.append('./stylegan3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AzzsYx1mGTF",
        "outputId": "fa608815-b0b6-40e9-809d-dc65922e9e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk2u40GwuJuo",
        "outputId": "e1f67df6-5fa6-4595-d76c-8f5102594088"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-25 10:21:23--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 35.160.122.182, 54.214.150.211\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|35.160.122.182|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-r-ffhqu-1024x1024.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCr6a8XN5syVWxxL9hmrCpuY3BAtX1eqWNeoIe5NQTqHAIhAJ7Y%2FvXn19rp5EOgbjdMG7Cv3CdHaTQ0NOj7vPdYT%2B%2BRKtsECIv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMNzg5MzYzMTM1MDI3Igx2nU87pmw59DdDkWEqrwRRxIlaICMkWClbrmhqNaSsmWUpimr9UOAWiv0P0rqUa7Te8CaE7dvGUXXJwfDr%2BrUo844HzbtR0ptl93x8LqLq6ZHegRdY%2Bx1iEQFD3Xm9UWsCDf59iRjg9FPMWfj1wSCMlVIytVF7JUzDrMcon%2BA1jZyKjO%2F0BpMc2p1O7hllx6SkNZtoMMnAFVklZB0lR2sTqKbBe2yhuXGjHqXBhuhx%2BwicBrP4qKEUDfy3FX7b0pk4d%2FUUZbxJmqSri3qQw4nrQDMUmbASDz6M3qcWsS%2BPcRCe86hogVSoCm9nsXvtmFipb3PJ4xvVvkOnsplreTOqSoVNaM8654PWKUCw4%2FgljwxZPXO4XKaOCtaqE44TsqS%2BhKc4iDF7WD6kE3aTQRsczuvfYPniabIZdgUPDvb%2BV%2BF85mSp%2FZqIQxNH71QaA9HiklcQyuw%2FjZIowDvJLU%2FwLFr%2FJeSPrffS7zrkol0NlC713B1IDYiih2ijES2zcHr0F2Nk2st5l9JC253z3XWgz%2FQYtsV3EcV9ALL8RBDZSkvItrLtUI7KKtvS8ZaRd6%2B%2FefY1fBQ%2Bpg5P36zl6P8SvrxA9lxw7w4GMF26v3tDK2PCZXHB7AutcxN6TDuC1L45rYB%2FRTpSSg%2Fe7t5EyeRvSF5d3zHFq31rZufjeG7WWy6nyswgAs70MYXGZFYo9cyxdfmo%2BQpUY601AssvKKzSzot3Fcyy9rrHx%2F0jcaDaMuVGEzzvH%2BtHvHTPpk%2FxMJ7wt5QGOqgBhlQXc%2FDrF2E%2Biibq2z9WGDhQbBzB3SolaRSAqa7CcCqlta0yVGk1fNDndfzERKa4FplHJh%2F2xX4PZL8gMX%2B6J5trnC8u1ucVwpOoJ43H3X5JBK8JIO7U90wf%2FXkJuViWXGRknijUidH9I88UyOYTbv%2FzWcB6CF1RmBUskouOB0WoiTw1T9L0GB3gfSnj9pW63ikdAmJwd4UnAuvOzxT%2Fvr9YLZPQ0CGO&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220525T102124Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZ7U5IKOZD%2F20220525%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=c66f4ced27aed9a1858d9ffb30695ddb123ce92910b3d0c4d0678af6cb0069a5 [following]\n",
            "--2022-05-25 10:21:24--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-r-ffhqu-1024x1024.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCr6a8XN5syVWxxL9hmrCpuY3BAtX1eqWNeoIe5NQTqHAIhAJ7Y%2FvXn19rp5EOgbjdMG7Cv3CdHaTQ0NOj7vPdYT%2B%2BRKtsECIv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMNzg5MzYzMTM1MDI3Igx2nU87pmw59DdDkWEqrwRRxIlaICMkWClbrmhqNaSsmWUpimr9UOAWiv0P0rqUa7Te8CaE7dvGUXXJwfDr%2BrUo844HzbtR0ptl93x8LqLq6ZHegRdY%2Bx1iEQFD3Xm9UWsCDf59iRjg9FPMWfj1wSCMlVIytVF7JUzDrMcon%2BA1jZyKjO%2F0BpMc2p1O7hllx6SkNZtoMMnAFVklZB0lR2sTqKbBe2yhuXGjHqXBhuhx%2BwicBrP4qKEUDfy3FX7b0pk4d%2FUUZbxJmqSri3qQw4nrQDMUmbASDz6M3qcWsS%2BPcRCe86hogVSoCm9nsXvtmFipb3PJ4xvVvkOnsplreTOqSoVNaM8654PWKUCw4%2FgljwxZPXO4XKaOCtaqE44TsqS%2BhKc4iDF7WD6kE3aTQRsczuvfYPniabIZdgUPDvb%2BV%2BF85mSp%2FZqIQxNH71QaA9HiklcQyuw%2FjZIowDvJLU%2FwLFr%2FJeSPrffS7zrkol0NlC713B1IDYiih2ijES2zcHr0F2Nk2st5l9JC253z3XWgz%2FQYtsV3EcV9ALL8RBDZSkvItrLtUI7KKtvS8ZaRd6%2B%2FefY1fBQ%2Bpg5P36zl6P8SvrxA9lxw7w4GMF26v3tDK2PCZXHB7AutcxN6TDuC1L45rYB%2FRTpSSg%2Fe7t5EyeRvSF5d3zHFq31rZufjeG7WWy6nyswgAs70MYXGZFYo9cyxdfmo%2BQpUY601AssvKKzSzot3Fcyy9rrHx%2F0jcaDaMuVGEzzvH%2BtHvHTPpk%2FxMJ7wt5QGOqgBhlQXc%2FDrF2E%2Biibq2z9WGDhQbBzB3SolaRSAqa7CcCqlta0yVGk1fNDndfzERKa4FplHJh%2F2xX4PZL8gMX%2B6J5trnC8u1ucVwpOoJ43H3X5JBK8JIO7U90wf%2FXkJuViWXGRknijUidH9I88UyOYTbv%2FzWcB6CF1RmBUskouOB0WoiTw1T9L0GB3gfSnj9pW63ikdAmJwd4UnAuvOzxT%2Fvr9YLZPQ0CGO&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220525T102124Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZ7U5IKOZD%2F20220525%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=c66f4ced27aed9a1858d9ffb30695ddb123ce92910b3d0c4d0678af6cb0069a5\n",
            "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.242.105\n",
            "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.242.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 237040122 (226M) [application/octet-stream]\n",
            "Saving to: ‘stylegan3-r-ffhqu-1024x1024.pkl’\n",
            "\n",
            "stylegan3-r-ffhqu-1 100%[===================>] 226.06M  43.8MB/s    in 5.4s    \n",
            "\n",
            "2022-05-25 10:21:30 (42.0 MB/s) - ‘stylegan3-r-ffhqu-1024x1024.pkl’ saved [237040122/237040122]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhqu-1024x1024.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GEzlx9nDKEO",
        "outputId": "fecc424a-f4fc-47b6-e12b-ca566abbb755"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-25 07:10:07--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhqu-1024x1024.pkl\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.8.244.123, 52.53.133.234\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.8.244.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-ffhqu-1024x1024.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-t-ffhqu-1024x1024.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJ%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMSJIMEYCIQDLOgeRu2v03mZGcGtlePWJJHT6r59KC6LLeEdrvvNAggIhAIKb%2BeybXulF0ng1PFg1gJYCUvErM1QV1YT8yr3cDEjlKtsECIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMNzg5MzYzMTM1MDI3IgzkwswbYvIKcfMlZ6UqrwSeiN8Zk1neXu9qlVFfFqf6k8JjwY%2FRpe56JPOVkn6hCBEuSZYiXgs5K7aGdjgnZ48vAKKnM5UFefgenxcm3CjJD5x2gUXEl5r%2FFKtdqovjEHejzKsayy5%2FFuu%2BTEXQ5yC%2FQJqzAD5P7Wq0cNvNllu5MO7DhcQKnmznIq1DoA1nDwfi5QqiENiPhkCWcwJ8Fbrg5G6IeyGzZGHkCBcYFSmT2h9PfnbNngVcoQD%2BdSX0zSodZWRT34rQsN4ZWJYJofP1yFeTgNdV9GSV%2FpEDfVKskJxwJ1i6lfMSWJiT96SU7lCBLzgh%2FBFqXjXVT3OfQJijHrWrvqsiUYAKRuGxapQTTW%2BAbYgK9xjvwF7s9mv5avdFsuciNt9aWhL2Au5%2FYRIsekNOI2m7D7gahZ553ComYR3kss%2BRt6mbnqNYt%2F5JQPY8E%2Bi5s812%2B26fElcmH0uz0kvHmHBBl3J4SRU4NIQqe0xI%2B0YdJT4Yw8cDEhfUQkoiaegqxzaIqpqGAfDQjP8sIcSsf6bqWUl6Vk3vPwBf6Sug5f%2F36Zi2nIRNj%2BPydCm78BR4G3ENd2bIgN5SnhPX2K5rjG9U86kpxoQMH41YqeYVKvDME77Z4PqghzlqS7Q0w6cKGfWPQG8oUFSoMPl%2ByG9JDj5zBAYDfNoF6dES2e2mLT5Qbz8Tnh0DgtNGwj3RgvDwAdTIcZd9c8AEbLea3vpw0k78SKlNMDNrawRUEwZ6qxGVf1z%2Bpgf%2BOy8aMJyrt5QGOqgBBg2%2BtLhck%2BOhb%2B%2F54Z%2BPmi%2FvBDePtDJKA4Tmv%2BNnU367%2BeF4MBqdt0J0bBFgJVkq3CFH%2FVxfWr46n3Ukrj538OZPrqMpX1lkiU9KHfyCxmnaD%2Fg0Cn0PKyrGVSSQdAMpo8aaTzc%2Bzr0vI6SLWyxmevfEym%2FtNIJ6Vs4OAEWEJiQzYXMxWKJTkhDAC7328ve4d0YNamHfFj4CJrATnb9V9Vidnh%2B%2F5MKf&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220525T071009Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZUZQ2374P%2F20220525%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=e8233d9479d79a4d9b0ae3edbb0cfa79729631a0029e863f8e54194879700984 [following]\n",
            "--2022-05-25 07:10:09--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-ffhqu-1024x1024.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-t-ffhqu-1024x1024.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJ%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMSJIMEYCIQDLOgeRu2v03mZGcGtlePWJJHT6r59KC6LLeEdrvvNAggIhAIKb%2BeybXulF0ng1PFg1gJYCUvErM1QV1YT8yr3cDEjlKtsECIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMNzg5MzYzMTM1MDI3IgzkwswbYvIKcfMlZ6UqrwSeiN8Zk1neXu9qlVFfFqf6k8JjwY%2FRpe56JPOVkn6hCBEuSZYiXgs5K7aGdjgnZ48vAKKnM5UFefgenxcm3CjJD5x2gUXEl5r%2FFKtdqovjEHejzKsayy5%2FFuu%2BTEXQ5yC%2FQJqzAD5P7Wq0cNvNllu5MO7DhcQKnmznIq1DoA1nDwfi5QqiENiPhkCWcwJ8Fbrg5G6IeyGzZGHkCBcYFSmT2h9PfnbNngVcoQD%2BdSX0zSodZWRT34rQsN4ZWJYJofP1yFeTgNdV9GSV%2FpEDfVKskJxwJ1i6lfMSWJiT96SU7lCBLzgh%2FBFqXjXVT3OfQJijHrWrvqsiUYAKRuGxapQTTW%2BAbYgK9xjvwF7s9mv5avdFsuciNt9aWhL2Au5%2FYRIsekNOI2m7D7gahZ553ComYR3kss%2BRt6mbnqNYt%2F5JQPY8E%2Bi5s812%2B26fElcmH0uz0kvHmHBBl3J4SRU4NIQqe0xI%2B0YdJT4Yw8cDEhfUQkoiaegqxzaIqpqGAfDQjP8sIcSsf6bqWUl6Vk3vPwBf6Sug5f%2F36Zi2nIRNj%2BPydCm78BR4G3ENd2bIgN5SnhPX2K5rjG9U86kpxoQMH41YqeYVKvDME77Z4PqghzlqS7Q0w6cKGfWPQG8oUFSoMPl%2ByG9JDj5zBAYDfNoF6dES2e2mLT5Qbz8Tnh0DgtNGwj3RgvDwAdTIcZd9c8AEbLea3vpw0k78SKlNMDNrawRUEwZ6qxGVf1z%2Bpgf%2BOy8aMJyrt5QGOqgBBg2%2BtLhck%2BOhb%2B%2F54Z%2BPmi%2FvBDePtDJKA4Tmv%2BNnU367%2BeF4MBqdt0J0bBFgJVkq3CFH%2FVxfWr46n3Ukrj538OZPrqMpX1lkiU9KHfyCxmnaD%2Fg0Cn0PKyrGVSSQdAMpo8aaTzc%2Bzr0vI6SLWyxmevfEym%2FtNIJ6Vs4OAEWEJiQzYXMxWKJTkhDAC7328ve4d0YNamHfFj4CJrATnb9V9Vidnh%2B%2F5MKf&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220525T071009Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZUZQ2374P%2F20220525%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=e8233d9479d79a4d9b0ae3edbb0cfa79729631a0029e863f8e54194879700984\n",
            "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.185.73\n",
            "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.185.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 294775122 (281M) [application/octet-stream]\n",
            "Saving to: ‘stylegan3-t-ffhqu-1024x1024.pkl’\n",
            "\n",
            "stylegan3-t-ffhqu-1 100%[===================>] 281.12M  30.7MB/s    in 9.2s    \n",
            "\n",
            "2022-05-25 07:10:18 (30.6 MB/s) - ‘stylegan3-t-ffhqu-1024x1024.pkl’ saved [294775122/294775122]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "np.random.seed(0)\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "z60-hgq7wES8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import librosa\n",
        "import cv2\n",
        "\n",
        "def make_transform(translate, angle):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "    \n",
        "class AudioEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AudioEncoder, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(1, 3, (3, 3))\n",
        "        self.feature_extractor = timm.create_model(\"resnet18\", num_classes=512, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/32\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      # return norm1(self.model.encode_image(self.normalize(image)))\n",
        "      return norm1(self.model.encode_image(image))\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "  ])\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def run(timestring):\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  # Init\n",
        "  # Sample 32 inits and choose the one closest to prompt\n",
        "\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(8):\n",
        "      q = (G.mapping(torch.randn([4,G.mapping.z_dim], device=device), None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
        "      images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).requires_grad_()\n",
        "\n",
        "  w_init = (q * w_stds + G.mapping.w_avg).detach().clone()\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  opt = torch.optim.AdamW([q], lr=0.03, betas=(0.0,0.999))\n",
        "  loop = tqdm(range(steps))\n",
        "  for i in loop:\n",
        "    \n",
        "    \n",
        "    w = q * w_stds + G.mapping.w_avg\n",
        "    \n",
        "    image = G.synthesis(w , noise_mode='const')\n",
        "   \n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = 0.1 *  prompts_dist_loss(embed, targets, spherical_dist_loss).mean() + ((w - w_init) ** 2).mean()\n",
        "    # loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    q_ema = q_ema * 0.9 + q * 0.1\n",
        "\n",
        "    final_code = q_ema * w_stds + G.mapping.w_avg\n",
        "    final_code[:,6:,:] = w_init[:,6:,:]\n",
        "    image = G.synthesis(final_code, noise_mode='const')\n",
        "\n",
        "    if i % 10 == 9 or i % 10 == 0:\n",
        "      # display(TF.to_pil_image(tf(image)[0]))\n",
        "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1).cpu())\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "model_url = \"/content/stylegan3-r-ffhqu-1024x1024.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths G.synthesis.input.transform= \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/giggling.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaSsKN1AESAe",
        "outputId": "9e2e4216-5f8b-461a-fea9-2538ccc2a25f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 248MiB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/200 [00:00<02:54,  1.14it/s, loss=0.108, q_magnitude=0.713]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0/200 | Current loss: 0.10817337036132812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [00:07<02:34,  1.23it/s, loss=0.108, q_magnitude=0.735]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 9/200 | Current loss: 0.10820405185222626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [00:08<02:33,  1.23it/s, loss=0.109, q_magnitude=0.735]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 10/200 | Current loss: 0.10936354100704193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 20/200 [00:15<02:26,  1.23it/s, loss=0.111, q_magnitude=0.731]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 19/200 | Current loss: 0.11061358451843262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:16<02:25,  1.23it/s, loss=0.11, q_magnitude=0.731]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 20/200 | Current loss: 0.1101084053516388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 30/200 [00:23<02:17,  1.23it/s, loss=0.118, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 29/200 | Current loss: 0.11830809712409973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [00:23<02:17,  1.23it/s, loss=0.119, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 30/200 | Current loss: 0.1185401976108551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [00:30<02:09,  1.24it/s, loss=0.124, q_magnitude=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 39/200 | Current loss: 0.12437185645103455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [00:31<02:09,  1.23it/s, loss=0.122, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 40/200 | Current loss: 0.12222114205360413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:38<02:01,  1.24it/s, loss=0.126, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 49/200 | Current loss: 0.12639446556568146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [00:39<02:01,  1.23it/s, loss=0.124, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 50/200 | Current loss: 0.12351733446121216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 60/200 [00:46<01:53,  1.23it/s, loss=0.124, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 59/200 | Current loss: 0.12420666217803955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [00:46<01:53,  1.23it/s, loss=0.124, q_magnitude=0.752]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 60/200 | Current loss: 0.12447169423103333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:53<01:45,  1.24it/s, loss=0.123, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 69/200 | Current loss: 0.12263815104961395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [00:54<01:44,  1.23it/s, loss=0.122, q_magnitude=0.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 70/200 | Current loss: 0.12234220653772354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [01:01<01:37,  1.24it/s, loss=0.122, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 79/200 | Current loss: 0.12162118405103683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [01:02<01:36,  1.23it/s, loss=0.123, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 80/200 | Current loss: 0.12285733222961426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [01:08<01:29,  1.24it/s, loss=0.132, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 89/200 | Current loss: 0.13179849088191986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [01:09<01:28,  1.23it/s, loss=0.133, q_magnitude=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 90/200 | Current loss: 0.13323378562927246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:16<01:21,  1.23it/s, loss=0.131, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 99/200 | Current loss: 0.13050979375839233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [01:17<01:20,  1.23it/s, loss=0.131, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 100/200 | Current loss: 0.13056722283363342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 110/200 [01:24<01:12,  1.24it/s, loss=0.127, q_magnitude=0.759]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 109/200 | Current loss: 0.12650302052497864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [01:25<01:12,  1.23it/s, loss=0.126, q_magnitude=0.761]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 110/200 | Current loss: 0.12647968530654907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 120/200 [01:31<01:04,  1.24it/s, loss=0.171, q_magnitude=0.79]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 119/200 | Current loss: 0.1714884638786316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [01:32<01:04,  1.23it/s, loss=0.173, q_magnitude=0.795]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 120/200 | Current loss: 0.1725119650363922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 130/200 [01:39<00:56,  1.23it/s, loss=0.178, q_magnitude=0.803]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 129/200 | Current loss: 0.17838642001152039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [01:40<00:56,  1.23it/s, loss=0.177, q_magnitude=0.803]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 130/200 | Current loss: 0.1769060492515564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 140/200 [01:47<00:48,  1.24it/s, loss=0.161, q_magnitude=0.796]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 139/200 | Current loss: 0.1609884798526764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [01:48<00:47,  1.23it/s, loss=0.163, q_magnitude=0.796]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 140/200 | Current loss: 0.16342203319072723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [01:54<00:40,  1.24it/s, loss=0.163, q_magnitude=0.788]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 149/200 | Current loss: 0.16339629888534546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [01:55<00:39,  1.23it/s, loss=0.168, q_magnitude=0.787]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 150/200 | Current loss: 0.16825410723686218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [02:02<00:32,  1.23it/s, loss=0.167, q_magnitude=0.792]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 159/200 | Current loss: 0.16666974127292633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [02:03<00:31,  1.23it/s, loss=0.164, q_magnitude=0.792]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 160/200 | Current loss: 0.16422808170318604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 170/200 [02:10<00:24,  1.24it/s, loss=0.159, q_magnitude=0.795]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 169/200 | Current loss: 0.1593865156173706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [02:11<00:23,  1.23it/s, loss=0.158, q_magnitude=0.795]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 170/200 | Current loss: 0.157772958278656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 180/200 [02:17<00:16,  1.23it/s, loss=0.157, q_magnitude=0.793]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 179/200 | Current loss: 0.15706110000610352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [02:18<00:15,  1.23it/s, loss=0.16, q_magnitude=0.793]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 180/200 | Current loss: 0.16013921797275543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [02:25<00:08,  1.24it/s, loss=0.162, q_magnitude=0.803]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 189/200 | Current loss: 0.16159197688102722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [02:26<00:07,  1.23it/s, loss=0.161, q_magnitude=0.804]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 190/200 | Current loss: 0.16140927374362946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:33<00:00,  1.31it/s, loss=0.166, q_magnitude=0.804]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 199/200 | Current loss: 0.16579735279083252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import librosa\n",
        "import cv2\n",
        "\n",
        "def make_transform(translate, angle):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "    \n",
        "class AudioEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AudioEncoder, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(1, 3, (3, 3))\n",
        "        self.feature_extractor = timm.create_model(\"resnet18\", num_classes=512, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/32\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      # return norm1(self.model.encode_image(self.normalize(image)))\n",
        "      return norm1(self.model.encode_image(image))\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "  ])\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def run(timestring):\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  # Init\n",
        "  # Sample 32 inits and choose the one closest to prompt\n",
        "\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(8):\n",
        "      q = (G.mapping(torch.randn([4,G.mapping.z_dim], device=device), None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
        "      images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).requires_grad_()\n",
        "\n",
        "  w_init = (q * w_stds + G.mapping.w_avg).detach().clone()\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  opt = torch.optim.AdamW([q], lr=0.03, betas=(0.0,0.999))\n",
        "  loop = tqdm(range(steps))\n",
        "  for i in loop:\n",
        "    \n",
        "    \n",
        "    w = q * w_stds + G.mapping.w_avg\n",
        "    \n",
        "    image = G.synthesis(w , noise_mode='const')\n",
        "   \n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = 0.1 *  prompts_dist_loss(embed, targets, spherical_dist_loss).mean() + ((w - w_init) ** 2).mean()\n",
        "    # loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    q_ema = q_ema * 0.9 + q * 0.1\n",
        "\n",
        "    final_code = q_ema * w_stds + G.mapping.w_avg\n",
        "    final_code[:,6:,:] = w_init[:,6:,:]\n",
        "    image = G.synthesis(final_code, noise_mode='const')\n",
        "\n",
        "    if i % 10 == 9 or i % 10 == 0:\n",
        "      # display(TF.to_pil_image(tf(image)[0]))\n",
        "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1).cpu())\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "model_url = \"/content/stylegan3-r-ffhqu-1024x1024.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "  \n",
        "shift = G.synthesis.input.affine(G.mapping.w_avg.unsqueeze(0))\n",
        "G.synthesis.input.affine.bias.data.add_(shift.squeeze(0))\n",
        "G.synthesis.input.affine.weight.data.zero_()\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths G.synthesis.input.transform= \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/giggling.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4UvkEsWzbDu",
        "outputId": "8f056d02-c757-46e4-9fa2-80e627f8454e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n",
            "  0%|          | 1/200 [00:00<02:41,  1.23it/s, loss=0.108, q_magnitude=0.715]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0/200 | Current loss: 0.10803081095218658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [00:07<02:33,  1.24it/s, loss=0.105, q_magnitude=0.732]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 9/200 | Current loss: 0.1049620509147644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [00:08<02:33,  1.23it/s, loss=0.105, q_magnitude=0.732]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 10/200 | Current loss: 0.1052856370806694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 20/200 [00:15<02:25,  1.24it/s, loss=0.106, q_magnitude=0.727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 19/200 | Current loss: 0.10621203482151031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:16<02:25,  1.23it/s, loss=0.106, q_magnitude=0.727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 20/200 | Current loss: 0.10582180321216583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 30/200 [00:22<02:17,  1.23it/s, loss=0.112, q_magnitude=0.73]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 29/200 | Current loss: 0.11163359880447388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [00:23<02:17,  1.23it/s, loss=0.113, q_magnitude=0.732]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 30/200 | Current loss: 0.11255566775798798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [00:30<02:15,  1.18it/s, loss=0.114, q_magnitude=0.737]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 39/200 | Current loss: 0.11418335139751434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [00:31<02:13,  1.19it/s, loss=0.113, q_magnitude=0.737]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 40/200 | Current loss: 0.11317933350801468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:38<02:01,  1.23it/s, loss=0.111, q_magnitude=0.738]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 49/200 | Current loss: 0.11122281849384308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [00:39<02:01,  1.23it/s, loss=0.111, q_magnitude=0.739]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 50/200 | Current loss: 0.11058922857046127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 60/200 [00:46<01:53,  1.24it/s, loss=0.113, q_magnitude=0.741]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 59/200 | Current loss: 0.11315984278917313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [00:46<01:52,  1.23it/s, loss=0.114, q_magnitude=0.741]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 60/200 | Current loss: 0.11370810866355896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:53<01:45,  1.24it/s, loss=0.114, q_magnitude=0.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 69/200 | Current loss: 0.11386634409427643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [00:54<01:44,  1.23it/s, loss=0.113, q_magnitude=0.739]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 70/200 | Current loss: 0.11291210353374481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [01:01<01:37,  1.24it/s, loss=0.114, q_magnitude=0.736]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 79/200 | Current loss: 0.11379910260438919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [01:02<01:36,  1.23it/s, loss=0.115, q_magnitude=0.737]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 80/200 | Current loss: 0.11529497057199478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [01:09<01:28,  1.24it/s, loss=0.115, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 89/200 | Current loss: 0.11473555862903595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [01:09<01:28,  1.23it/s, loss=0.114, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 90/200 | Current loss: 0.11426292359828949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:16<01:20,  1.24it/s, loss=0.115, q_magnitude=0.738]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 99/200 | Current loss: 0.11535884439945221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [01:17<01:20,  1.23it/s, loss=0.117, q_magnitude=0.738]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 100/200 | Current loss: 0.11665884405374527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 110/200 [01:24<01:12,  1.24it/s, loss=0.116, q_magnitude=0.741]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 109/200 | Current loss: 0.11575715243816376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [01:25<01:12,  1.23it/s, loss=0.114, q_magnitude=0.742]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 110/200 | Current loss: 0.1144484281539917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 120/200 [01:31<01:04,  1.23it/s, loss=0.119, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 119/200 | Current loss: 0.11877453327178955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [01:32<01:04,  1.23it/s, loss=0.121, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 120/200 | Current loss: 0.1206476241350174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 130/200 [01:39<00:56,  1.24it/s, loss=0.119, q_magnitude=0.744]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 129/200 | Current loss: 0.11918725073337555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [01:40<00:56,  1.23it/s, loss=0.121, q_magnitude=0.744]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 130/200 | Current loss: 0.12089578062295914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 140/200 [01:47<00:48,  1.24it/s, loss=0.121, q_magnitude=0.752]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 139/200 | Current loss: 0.12063277512788773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [01:48<00:47,  1.23it/s, loss=0.121, q_magnitude=0.752]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 140/200 | Current loss: 0.12079565227031708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [01:54<00:40,  1.24it/s, loss=0.121, q_magnitude=0.756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 149/200 | Current loss: 0.12053963541984558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [01:55<00:39,  1.23it/s, loss=0.121, q_magnitude=0.754]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 150/200 | Current loss: 0.12133058905601501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [02:02<00:32,  1.23it/s, loss=0.121, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 159/200 | Current loss: 0.12087911367416382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [02:03<00:31,  1.23it/s, loss=0.121, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 160/200 | Current loss: 0.12067320942878723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 170/200 [02:10<00:24,  1.24it/s, loss=0.122, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 169/200 | Current loss: 0.12157247215509415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [02:11<00:23,  1.23it/s, loss=0.12, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 170/200 | Current loss: 0.1203116625547409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 180/200 [02:17<00:16,  1.23it/s, loss=0.135, q_magnitude=0.772]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 179/200 | Current loss: 0.13519155979156494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [02:18<00:15,  1.23it/s, loss=0.14, q_magnitude=0.778]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 180/200 | Current loss: 0.13964378833770752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [02:25<00:08,  1.24it/s, loss=0.163, q_magnitude=0.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 189/200 | Current loss: 0.16344869136810303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [02:26<00:07,  1.23it/s, loss=0.163, q_magnitude=0.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 190/200 | Current loss: 0.16318482160568237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:33<00:00,  1.31it/s, loss=0.151, q_magnitude=0.795]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 199/200 | Current loss: 0.1507500261068344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import librosa\n",
        "import cv2\n",
        "\n",
        "def make_transform(translate, angle):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "    \n",
        "class AudioEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AudioEncoder, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(1, 3, (3, 3))\n",
        "        self.feature_extractor = timm.create_model(\"resnet18\", num_classes=512, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/32\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      # return norm1(self.model.encode_image(self.normalize(image)))\n",
        "      return norm1(self.model.encode_image(image))\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "  ])\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def run(timestring):\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  # Init\n",
        "  # Sample 32 inits and choose the one closest to prompt\n",
        "\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(8):\n",
        "      q = (G.mapping(torch.randn([4,G.mapping.z_dim], device=device), None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
        "      images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).requires_grad_()\n",
        "\n",
        "  w_init = (q * w_stds + G.mapping.w_avg).detach().clone()\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  opt = torch.optim.AdamW([q], lr=0.03, betas=(0.0,0.999))\n",
        "  loop = tqdm(range(steps))\n",
        "  for i in loop:\n",
        "    \n",
        "    \n",
        "    w = q * w_stds + G.mapping.w_avg\n",
        "    \n",
        "    image = G.synthesis(w , noise_mode='const')\n",
        "   \n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = 0.1 *  prompts_dist_loss(embed, targets, spherical_dist_loss).mean() + ((w - w_init) ** 2).mean()\n",
        "    # loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    q_ema = q_ema * 0.9 + q * 0.1\n",
        "\n",
        "    final_code = q_ema * w_stds + G.mapping.w_avg\n",
        "    final_code[:,6:,:] = w_init[:,6:,:]\n",
        "    image = G.synthesis(final_code, noise_mode='const')\n",
        "\n",
        "    if i % 10 == 9 or i % 10 == 0:\n",
        "      # display(TF.to_pil_image(tf(image)[0]))\n",
        "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1).cpu())\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "model_url = \"/content/stylegan3-r-ffhqu-1024x1024.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "  \n",
        "shift = G.synthesis.input.affine(G.mapping.w_avg.unsqueeze(0))\n",
        "G.synthesis.input.affine.bias.data.add_(shift.squeeze(0))\n",
        "G.synthesis.input.affine.weight.data.zero_()\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths G.synthesis.input.transform= \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/giggling.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy5tkLZCza8b",
        "outputId": "2554d88e-f345-4a2e-eca0-70e13656b80f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n",
            "  0%|          | 1/200 [00:00<02:42,  1.23it/s, loss=0.108, q_magnitude=0.715]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0/200 | Current loss: 0.10803081095218658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [00:07<02:33,  1.24it/s, loss=0.104, q_magnitude=0.727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 9/200 | Current loss: 0.1042117103934288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [00:08<02:33,  1.23it/s, loss=0.104, q_magnitude=0.727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 10/200 | Current loss: 0.10412921011447906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 20/200 [00:15<02:26,  1.23it/s, loss=0.107, q_magnitude=0.736]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 19/200 | Current loss: 0.10718690603971481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:16<02:26,  1.23it/s, loss=0.109, q_magnitude=0.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 20/200 | Current loss: 0.10903249680995941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 30/200 [00:22<02:17,  1.23it/s, loss=0.116, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 29/200 | Current loss: 0.11573070287704468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [00:23<02:17,  1.23it/s, loss=0.115, q_magnitude=0.744]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 30/200 | Current loss: 0.11474645137786865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [00:30<02:09,  1.24it/s, loss=0.112, q_magnitude=0.734]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 39/200 | Current loss: 0.11228205263614655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [00:31<02:08,  1.23it/s, loss=0.113, q_magnitude=0.734]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 40/200 | Current loss: 0.11251592636108398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:38<02:01,  1.24it/s, loss=0.112, q_magnitude=0.737]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 49/200 | Current loss: 0.11219648271799088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [00:39<02:01,  1.23it/s, loss=0.112, q_magnitude=0.737]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 50/200 | Current loss: 0.11150842905044556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 60/200 [00:45<01:53,  1.24it/s, loss=0.114, q_magnitude=0.739]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 59/200 | Current loss: 0.11369093507528305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [00:46<01:53,  1.23it/s, loss=0.115, q_magnitude=0.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 60/200 | Current loss: 0.11499877274036407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:53<01:45,  1.24it/s, loss=0.114, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 69/200 | Current loss: 0.11385664343833923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [00:54<01:44,  1.23it/s, loss=0.113, q_magnitude=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 70/200 | Current loss: 0.1128951758146286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [01:01<01:37,  1.24it/s, loss=0.115, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 79/200 | Current loss: 0.11528939008712769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [01:02<01:36,  1.23it/s, loss=0.116, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 80/200 | Current loss: 0.1164013221859932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [01:08<01:28,  1.24it/s, loss=0.116, q_magnitude=0.743]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 89/200 | Current loss: 0.11642690002918243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [01:09<01:28,  1.23it/s, loss=0.116, q_magnitude=0.743]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 90/200 | Current loss: 0.11600667983293533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:16<01:20,  1.24it/s, loss=0.118, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 99/200 | Current loss: 0.11790516972541809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [01:17<01:20,  1.23it/s, loss=0.12, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 100/200 | Current loss: 0.12003472447395325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 110/200 [01:24<01:12,  1.24it/s, loss=0.121, q_magnitude=0.752]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 109/200 | Current loss: 0.12105880677700043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [01:24<01:12,  1.23it/s, loss=0.12, q_magnitude=0.753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 110/200 | Current loss: 0.11977405101060867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 120/200 [01:31<01:04,  1.24it/s, loss=0.124, q_magnitude=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 119/200 | Current loss: 0.12372978776693344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [01:32<01:04,  1.23it/s, loss=0.125, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 120/200 | Current loss: 0.12478503584861755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 130/200 [01:39<00:56,  1.24it/s, loss=0.125, q_magnitude=0.755]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 129/200 | Current loss: 0.12499932199716568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [01:40<00:55,  1.23it/s, loss=0.127, q_magnitude=0.756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 130/200 | Current loss: 0.12743736803531647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 140/200 [01:47<00:48,  1.24it/s, loss=0.124, q_magnitude=0.753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 139/200 | Current loss: 0.12401944398880005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [01:47<00:47,  1.23it/s, loss=0.125, q_magnitude=0.753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 140/200 | Current loss: 0.12509766221046448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [01:54<00:40,  1.23it/s, loss=0.124, q_magnitude=0.758]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 149/200 | Current loss: 0.1241074949502945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [01:55<00:39,  1.23it/s, loss=0.125, q_magnitude=0.759]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 150/200 | Current loss: 0.1254909783601761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [02:02<00:32,  1.24it/s, loss=0.124, q_magnitude=0.755]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 159/200 | Current loss: 0.12442104518413544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [02:03<00:31,  1.23it/s, loss=0.125, q_magnitude=0.755]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 160/200 | Current loss: 0.1246735230088234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 170/200 [02:10<00:24,  1.24it/s, loss=0.125, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 169/200 | Current loss: 0.12539474666118622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [02:10<00:23,  1.23it/s, loss=0.124, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 170/200 | Current loss: 0.12365768849849701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 180/200 [02:17<00:16,  1.23it/s, loss=0.126, q_magnitude=0.756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 179/200 | Current loss: 0.12564441561698914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [02:18<00:15,  1.23it/s, loss=0.126, q_magnitude=0.756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 180/200 | Current loss: 0.12581640481948853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [02:25<00:08,  1.24it/s, loss=0.124, q_magnitude=0.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 189/200 | Current loss: 0.12424660474061966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [02:26<00:07,  1.23it/s, loss=0.123, q_magnitude=0.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 190/200 | Current loss: 0.12296846508979797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:33<00:00,  1.31it/s, loss=0.125, q_magnitude=0.755]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 199/200 | Current loss: 0.12532679736614227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import librosa\n",
        "import cv2\n",
        "\n",
        "def make_transform(translate, angle):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "    \n",
        "class AudioEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AudioEncoder, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(1, 3, (3, 3))\n",
        "        self.feature_extractor = timm.create_model(\"resnet18\", num_classes=512, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/32\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      # return norm1(self.model.encode_image(self.normalize(image)))\n",
        "      return norm1(self.model.encode_image(image))\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "  ])\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def run(timestring):\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  # Init\n",
        "  # Sample 32 inits and choose the one closest to prompt\n",
        "\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(8):\n",
        "      q = (G.mapping(torch.randn([4,G.mapping.z_dim], device=device), None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
        "      images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).requires_grad_()\n",
        "\n",
        "  w_init = (q * w_stds + G.mapping.w_avg).detach().clone()\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  opt = torch.optim.AdamW([q], lr=0.03, betas=(0.0,0.999))\n",
        "  loop = tqdm(range(steps))\n",
        "  for i in loop:\n",
        "    \n",
        "    \n",
        "    w = q * w_stds + G.mapping.w_avg\n",
        "    \n",
        "    image = G.synthesis(w , noise_mode='const')\n",
        "   \n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = 0.1 *  prompts_dist_loss(embed, targets, spherical_dist_loss).mean() + ((w - w_init) ** 2).mean()\n",
        "    # loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    q_ema = q_ema * 0.9 + q * 0.1\n",
        "\n",
        "    final_code = q_ema * w_stds + G.mapping.w_avg\n",
        "    final_code[:,6:,:] = w_init[:,6:,:]\n",
        "    image = G.synthesis(final_code, noise_mode='const')\n",
        "\n",
        "    if i % 10 == 9 or i % 10 == 0:\n",
        "      # display(TF.to_pil_image(tf(image)[0]))\n",
        "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1).cpu())\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "model_url = \"/content/stylegan3-r-ffhqu-1024x1024.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "  \n",
        "\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths G.synthesis.input.transform= \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/giggling.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBmSX7e2w8JR",
        "outputId": "f696793d-4fba-4f4a-bd45-163585406206"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n",
            "  0%|          | 1/200 [00:00<02:42,  1.22it/s, loss=0.108, q_magnitude=0.713]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0/200 | Current loss: 0.10817588865756989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [00:07<02:34,  1.23it/s, loss=0.109, q_magnitude=0.733]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 9/200 | Current loss: 0.10858478397130966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [00:08<02:33,  1.23it/s, loss=0.11, q_magnitude=0.733]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 10/200 | Current loss: 0.11010295152664185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 20/200 [00:15<02:25,  1.24it/s, loss=0.119, q_magnitude=0.736]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 19/200 | Current loss: 0.11857292056083679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:16<02:25,  1.23it/s, loss=0.119, q_magnitude=0.736]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 20/200 | Current loss: 0.11937723308801651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 30/200 [00:22<02:17,  1.23it/s, loss=0.119, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 29/200 | Current loss: 0.1190975084900856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [00:23<02:17,  1.23it/s, loss=0.12, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 30/200 | Current loss: 0.12030439078807831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [00:30<02:09,  1.24it/s, loss=0.127, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 39/200 | Current loss: 0.1271945983171463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [00:31<02:09,  1.23it/s, loss=0.121, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 40/200 | Current loss: 0.1211814135313034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:38<02:01,  1.24it/s, loss=0.13, q_magnitude=0.754]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 49/200 | Current loss: 0.129567950963974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [00:39<02:00,  1.23it/s, loss=0.129, q_magnitude=0.754]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 50/200 | Current loss: 0.12894009053707123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 60/200 [00:45<01:53,  1.23it/s, loss=0.128, q_magnitude=0.756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 59/200 | Current loss: 0.12755148112773895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [00:46<01:52,  1.23it/s, loss=0.128, q_magnitude=0.756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 60/200 | Current loss: 0.12795473635196686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:53<01:45,  1.24it/s, loss=0.127, q_magnitude=0.753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 69/200 | Current loss: 0.12665359675884247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [00:54<01:44,  1.23it/s, loss=0.126, q_magnitude=0.753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 70/200 | Current loss: 0.1264246255159378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [01:01<01:37,  1.24it/s, loss=0.149, q_magnitude=0.764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 79/200 | Current loss: 0.14930689334869385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [01:02<01:36,  1.23it/s, loss=0.152, q_magnitude=0.767]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 80/200 | Current loss: 0.15189723670482635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [01:08<01:29,  1.24it/s, loss=0.138, q_magnitude=0.768]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 89/200 | Current loss: 0.13759905099868774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [01:09<01:28,  1.23it/s, loss=0.138, q_magnitude=0.768]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 90/200 | Current loss: 0.1379435956478119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:16<01:21,  1.23it/s, loss=0.143, q_magnitude=0.774]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 99/200 | Current loss: 0.14261427521705627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [01:17<01:20,  1.23it/s, loss=0.144, q_magnitude=0.774]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 100/200 | Current loss: 0.14433400332927704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 110/200 [01:24<01:13,  1.23it/s, loss=0.141, q_magnitude=0.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 109/200 | Current loss: 0.14144589006900787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [01:25<01:12,  1.23it/s, loss=0.14, q_magnitude=0.769]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 110/200 | Current loss: 0.1396656334400177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 120/200 [01:31<01:04,  1.23it/s, loss=0.139, q_magnitude=0.769]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 119/200 | Current loss: 0.13878944516181946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [01:32<01:04,  1.23it/s, loss=0.141, q_magnitude=0.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 120/200 | Current loss: 0.14110355079174042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 130/200 [01:39<00:56,  1.24it/s, loss=0.146, q_magnitude=0.767]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 129/200 | Current loss: 0.14552898705005646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [01:40<00:55,  1.23it/s, loss=0.146, q_magnitude=0.765]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 130/200 | Current loss: 0.14606423676013947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 140/200 [01:47<00:48,  1.24it/s, loss=0.169, q_magnitude=0.774]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 139/200 | Current loss: 0.16907404363155365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [01:47<00:47,  1.23it/s, loss=0.168, q_magnitude=0.775]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 140/200 | Current loss: 0.16838139295578003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [01:54<00:40,  1.24it/s, loss=0.182, q_magnitude=0.801]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 149/200 | Current loss: 0.181901216506958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [01:55<00:39,  1.23it/s, loss=0.184, q_magnitude=0.804]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 150/200 | Current loss: 0.1837916374206543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [02:02<00:32,  1.23it/s, loss=0.198, q_magnitude=0.822]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 159/200 | Current loss: 0.19763195514678955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [02:03<00:31,  1.23it/s, loss=0.197, q_magnitude=0.823]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 160/200 | Current loss: 0.1972498595714569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 170/200 [02:10<00:24,  1.24it/s, loss=0.195, q_magnitude=0.825]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 169/200 | Current loss: 0.19523191452026367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [02:10<00:23,  1.23it/s, loss=0.194, q_magnitude=0.825]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 170/200 | Current loss: 0.19366523623466492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 180/200 [02:17<00:16,  1.24it/s, loss=0.206, q_magnitude=0.838]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 179/200 | Current loss: 0.20631740987300873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [02:18<00:15,  1.23it/s, loss=0.209, q_magnitude=0.84]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 180/200 | Current loss: 0.209242045879364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [02:25<00:08,  1.24it/s, loss=0.21, q_magnitude=0.845]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 189/200 | Current loss: 0.2098473757505417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [02:26<00:07,  1.23it/s, loss=0.208, q_magnitude=0.843]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 190/200 | Current loss: 0.20830826461315155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:33<00:00,  1.31it/s, loss=0.181, q_magnitude=0.825]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 199/200 | Current loss: 0.1811543107032776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StyleGAN3+++++.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcRRB3i8O+ZUk4lfcg7j4L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}