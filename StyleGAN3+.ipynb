{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN3+.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVkuIy7+hk/cIloaSPHMx+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjjuurang/CLIP/blob/main/StyleGAN3%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install --upgrade https://download.pytorch.org/whl/nightly/cu111/torch-1.11.0.dev20211012%2Bcu111-cp37-cp37m-linux_x86_64.whl https://download.pytorch.org/whl/nightly/cu111/torchvision-0.12.0.dev20211012%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "!git clone https://github.com/NVlabs/stylegan3\n",
        "!git clone https://github.com/openai/CLIP\n",
        "!pip install -e ./CLIP\n",
        "!pip install einops ninja\n",
        "\n",
        "import sys\n",
        "sys.path.append('./CLIP')\n",
        "sys.path.append('./stylegan3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMFvMqutlETj",
        "outputId": "12eb68ec-c497-4cb3-f2e0-abdc6da50dc9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:14:59tcmalloc: large alloc 1147494400 bytes == 0x3968a000 @  0x7f2f2f921615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:18tcmalloc: large alloc 1434370048 bytes == 0x7dce0000 @  0x7f2f2f921615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.3 MB/s eta 0:09:22tcmalloc: large alloc 1792966656 bytes == 0x2b12000 @  0x7f2f2f921615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.1 MB/s eta 0:05:08tcmalloc: large alloc 2241208320 bytes == 0x6d8fa000 @  0x7f2f2f921615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 2041315328 bytes == 0xf325c000 @  0x7f2f2f9201e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2551644160 bytes == 0x1e11a0000 @  0x7f2f2f921615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 8.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1+cu111) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1+cu111 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.1+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.1+cu111 torchvision-0.10.1+cu111\n",
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Total 207 (delta 0), reused 0 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (207/207), 4.16 MiB | 2.22 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n",
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Total 222 (delta 0), reused 0 (delta 0), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (222/222), 8.91 MiB | 18.00 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n",
            "Obtaining file:///content/CLIP\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.9.1+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.10.1+cu111)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Installing collected packages: ftfy, clip\n",
            "  Running setup.py develop for clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 54.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja, einops\n",
            "Successfully installed einops-0.4.1 ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AzzsYx1mGTF",
        "outputId": "77970da2-295a-4fab-ce17-b4e1b1b65b29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 40.8 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 41.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 44.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 26.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-afhqv2-512x512.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuKcvDLZoq_u",
        "outputId": "8068eeb2-13d9-4944-e0fb-432959f7a37b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 06:38:44--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-afhqv2-512x512.pkl\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 35.160.122.182, 54.214.150.211\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|35.160.122.182|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-afhqv2-512x512.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-t-afhqv2-512x512.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEG4aCXVzLXdlc3QtMiJGMEQCIAhJK%2FgRu0RTn%2BaEnoewj77uNliEsxCBc9mjPCif%2Bk50AiAHTf9qApt9XUsI441vH5cvSFqj97Nlwc1FDuvtw14HXSrSBAhXEAQaDDc4OTM2MzEzNTAyNyIMsfQluG9vJWnPKXohKq8EhINZHPsR0Ej2584a9e7HSji6xqkCLLT131RLsQn9nUh1xkj8BPUyXIpXEkixZjC6HAcDMP4f%2FjJSVlEW9S8opxuCpAds5x6xozk2yh2yHrysLQ4jlI7Y5Id4fHW5k6Q0bDFfFGcdopgS6C2cNPxGNGS81fzOR%2F4w75TKVre%2FY2hoAMLbqLQohdH2Exky7LR8yeLp07bmQ4TZCiQQIjyyxSXGCcqjer6dqqvDmrdNOnnyhRJSGhcykaO9KfRWcvYUMceNwDOEfl4H6pj5VWIC77UtxMRe%2FMbNBUoj8NzrGdoGzivJZnsmKDRVFDkwUnunzxINju3t8Xrj%2BNpcyFKkTwaR%2F74JcvOMW3p17UnibLEp6DyEVCqx3V8THpZaSs%2Bk%2FXlrmBCF6JT0OGZLSRv9QXoqzGJjSZB8GQEUEn2hpd%2F78njWN%2FfZ%2BMafnKDm7YySYvOvBqxDTRir7O5L4r5rfyOEhd72uHmSccXGIQaZX8YD0I0HVQXFME9M7LIyLOr%2Fgbpwoq697xzyTwemplqqXKxTQdTqPIJMcj5qjo0XMDaqyjXJ8UdlhyHr5vnPm2%2FyuwpPZtlpg0urYTRP2JGhj6GE0sUREYo70qVS3TdX4UVHUIkLFPxEdBAEYGFf%2BiyBtcSXTAD%2Bi7YEgY71Wcnqj5609dHFR8Ykruv0NVQyI03vCIr00%2FY8L3B%2Fh7ubNMNhYRSd0gtK%2B2TG4mkjQfPB1v056EK7RsbZmF76P7bcFTC%2BxqyUBjqqAaD%2BxBOsa9VPHq%2FsohPuKEMp2DV1IEnGutb34Cc01tkv%2FNGVG5y9MaH0013TVemWe1pPaqZ4zmkfrgONWuc66QNSo1DZY2Sihtt%2FXcRpdBK8yz4%2FtPRCHvmrAAlc27SjnuHTOXyujMQl01LpCfqq%2B1Nm3yJ0Wpzja2I9JsKxr%2FAnMjWMMT%2FLXD6%2BBmOehd8PhvO1dRoLT0SBaNBJtrarojzt3rHYO0YXbz8I&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220523T063846Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZ56BGF34O%2F20220523%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=5db8ca49dd3b600ba4044caaac02865d71a419e3e585b44d5a03c8bc03e4693d [following]\n",
            "--2022-05-23 06:38:46--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-afhqv2-512x512.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-t-afhqv2-512x512.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEG4aCXVzLXdlc3QtMiJGMEQCIAhJK%2FgRu0RTn%2BaEnoewj77uNliEsxCBc9mjPCif%2Bk50AiAHTf9qApt9XUsI441vH5cvSFqj97Nlwc1FDuvtw14HXSrSBAhXEAQaDDc4OTM2MzEzNTAyNyIMsfQluG9vJWnPKXohKq8EhINZHPsR0Ej2584a9e7HSji6xqkCLLT131RLsQn9nUh1xkj8BPUyXIpXEkixZjC6HAcDMP4f%2FjJSVlEW9S8opxuCpAds5x6xozk2yh2yHrysLQ4jlI7Y5Id4fHW5k6Q0bDFfFGcdopgS6C2cNPxGNGS81fzOR%2F4w75TKVre%2FY2hoAMLbqLQohdH2Exky7LR8yeLp07bmQ4TZCiQQIjyyxSXGCcqjer6dqqvDmrdNOnnyhRJSGhcykaO9KfRWcvYUMceNwDOEfl4H6pj5VWIC77UtxMRe%2FMbNBUoj8NzrGdoGzivJZnsmKDRVFDkwUnunzxINju3t8Xrj%2BNpcyFKkTwaR%2F74JcvOMW3p17UnibLEp6DyEVCqx3V8THpZaSs%2Bk%2FXlrmBCF6JT0OGZLSRv9QXoqzGJjSZB8GQEUEn2hpd%2F78njWN%2FfZ%2BMafnKDm7YySYvOvBqxDTRir7O5L4r5rfyOEhd72uHmSccXGIQaZX8YD0I0HVQXFME9M7LIyLOr%2Fgbpwoq697xzyTwemplqqXKxTQdTqPIJMcj5qjo0XMDaqyjXJ8UdlhyHr5vnPm2%2FyuwpPZtlpg0urYTRP2JGhj6GE0sUREYo70qVS3TdX4UVHUIkLFPxEdBAEYGFf%2BiyBtcSXTAD%2Bi7YEgY71Wcnqj5609dHFR8Ykruv0NVQyI03vCIr00%2FY8L3B%2Fh7ubNMNhYRSd0gtK%2B2TG4mkjQfPB1v056EK7RsbZmF76P7bcFTC%2BxqyUBjqqAaD%2BxBOsa9VPHq%2FsohPuKEMp2DV1IEnGutb34Cc01tkv%2FNGVG5y9MaH0013TVemWe1pPaqZ4zmkfrgONWuc66QNSo1DZY2Sihtt%2FXcRpdBK8yz4%2FtPRCHvmrAAlc27SjnuHTOXyujMQl01LpCfqq%2B1Nm3yJ0Wpzja2I9JsKxr%2FAnMjWMMT%2FLXD6%2BBmOehd8PhvO1dRoLT0SBaNBJtrarojzt3rHYO0YXbz8I&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220523T063846Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZ56BGF34O%2F20220523%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=5db8ca49dd3b600ba4044caaac02865d71a419e3e585b44d5a03c8bc03e4693d\n",
            "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.176.57\n",
            "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.176.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 315163814 (301M) [application/octet-stream]\n",
            "Saving to: ‘stylegan3-t-afhqv2-512x512.pkl’\n",
            "\n",
            "stylegan3-t-afhqv2- 100%[===================>] 300.56M  17.5MB/s    in 18s     \n",
            "\n",
            "2022-05-23 06:39:06 (16.3 MB/s) - ‘stylegan3-t-afhqv2-512x512.pkl’ saved [315163814/315163814]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2dST3fnhwd-",
        "outputId": "9f91d684-2f90-407b-d3c6-9cf4e88bd65e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n",
            "  0%|          | 1/200 [00:00<01:19,  2.50it/s, loss=0.115, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0/200 | Current loss: 0.11514697223901749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [00:03<01:16,  2.48it/s, loss=0.117, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 9/200 | Current loss: 0.11658503115177155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [00:04<01:15,  2.50it/s, loss=0.114, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 10/200 | Current loss: 0.11420343816280365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 20/200 [00:07<01:13,  2.46it/s, loss=0.113, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 19/200 | Current loss: 0.11251052469015121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:08<01:12,  2.48it/s, loss=0.111, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 20/200 | Current loss: 0.11145616322755814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 30/200 [00:11<01:09,  2.45it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 29/200 | Current loss: 0.11157096177339554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [00:11<01:08,  2.47it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 30/200 | Current loss: 0.1117543876171112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [00:15<01:06,  2.42it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 39/200 | Current loss: 0.11184442043304443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [00:15<01:04,  2.45it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 40/200 | Current loss: 0.11197835206985474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:19<01:01,  2.42it/s, loss=0.111, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 49/200 | Current loss: 0.11132191866636276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [00:19<01:01,  2.44it/s, loss=0.111, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 50/200 | Current loss: 0.11109700053930283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 60/200 [00:23<00:58,  2.41it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 59/200 | Current loss: 0.1121426671743393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [00:23<00:57,  2.43it/s, loss=0.113, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 60/200 | Current loss: 0.1125423014163971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:27<00:54,  2.39it/s, loss=0.112, q_magnitude=0.666]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 69/200 | Current loss: 0.11244366317987442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [00:27<00:53,  2.41it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 70/200 | Current loss: 0.11241307854652405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [00:31<00:50,  2.36it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 79/200 | Current loss: 0.11188983172178268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [00:31<00:49,  2.38it/s, loss=0.111, q_magnitude=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 80/200 | Current loss: 0.11142916232347488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [00:35<00:46,  2.36it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 89/200 | Current loss: 0.11193294823169708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [00:35<00:45,  2.38it/s, loss=0.112, q_magnitude=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 90/200 | Current loss: 0.11157742887735367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [00:39<00:42,  2.33it/s, loss=0.113, q_magnitude=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 99/200 | Current loss: 0.11331219971179962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [00:39<00:41,  2.36it/s, loss=0.114, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 100/200 | Current loss: 0.11378669738769531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 110/200 [00:43<00:38,  2.36it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 109/200 | Current loss: 0.11183404922485352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [00:43<00:37,  2.39it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 110/200 | Current loss: 0.11154626309871674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 120/200 [00:47<00:33,  2.37it/s, loss=0.111, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 119/200 | Current loss: 0.11057412624359131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [00:47<00:32,  2.40it/s, loss=0.111, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 120/200 | Current loss: 0.11107035726308823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 130/200 [00:51<00:29,  2.38it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 129/200 | Current loss: 0.11128796637058258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [00:51<00:28,  2.41it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 130/200 | Current loss: 0.1121176928281784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 140/200 [00:55<00:24,  2.40it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 139/200 | Current loss: 0.11107420176267624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [00:55<00:24,  2.43it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 140/200 | Current loss: 0.11161737889051437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [00:59<00:20,  2.42it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 149/200 | Current loss: 0.11095880717039108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [00:59<00:20,  2.44it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 150/200 | Current loss: 0.11124267429113388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [01:03<00:16,  2.42it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 159/200 | Current loss: 0.11097431927919388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [01:03<00:15,  2.44it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 160/200 | Current loss: 0.11153680831193924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 170/200 [01:06<00:12,  2.44it/s, loss=0.111, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 169/200 | Current loss: 0.11120787262916565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [01:07<00:11,  2.47it/s, loss=0.111, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 170/200 | Current loss: 0.11133819073438644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 180/200 [01:10<00:08,  2.43it/s, loss=0.112, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 179/200 | Current loss: 0.11202046275138855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [01:11<00:07,  2.45it/s, loss=0.113, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 180/200 | Current loss: 0.11255677789449692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [01:14<00:04,  2.43it/s, loss=0.116, q_magnitude=0.672]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 189/200 | Current loss: 0.11608592420816422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [01:15<00:03,  2.46it/s, loss=0.115, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 190/200 | Current loss: 0.11472124606370926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:18<00:00,  2.55it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 199/200 | Current loss: 0.1119939461350441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import librosa\n",
        "import cv2\n",
        "\n",
        "def make_transform(translate, angle):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "    \n",
        "class AudioEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AudioEncoder, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(1, 3, (3, 3))\n",
        "        self.feature_extractor = timm.create_model(\"resnet18\", num_classes=512, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/32\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      # return norm1(self.model.encode_image(self.normalize(image)))\n",
        "      return norm1(self.model.encode_image(image))\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "  ])\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def run(timestring):\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  # Init\n",
        "  # Sample 32 inits and choose the one closest to prompt\n",
        "\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(8):\n",
        "      q = (G.mapping(torch.randn([4,G.mapping.z_dim], device=device), None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
        "      images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).requires_grad_()\n",
        "\n",
        "  w_init = (q * w_stds + G.mapping.w_avg).detach().clone()\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  opt = torch.optim.AdamW([q], lr=0.03, betas=(0.0,0.999))\n",
        "  loop = tqdm(range(steps))\n",
        "  for i in loop:\n",
        "    opt.zero_grad()\n",
        "    w = q * w_stds + G.mapping.w_avg\n",
        "    image = G.synthesis(w , noise_mode='const')\n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = 0.1 *  prompts_dist_loss(embed, targets, spherical_dist_loss).mean() + ((w - w_init) ** 2).mean()\n",
        "    # loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    q_ema = q_ema * 0.9 + q * 0.1\n",
        "\n",
        "    final_code = q_ema * w_stds + G.mapping.w_avg\n",
        "    final_code[:,6:,:] = w_init[:,6:,:]\n",
        "    image = G.synthesis(final_code, noise_mode='const')\n",
        "\n",
        "    if i % 10 == 9 or i % 10 == 0:\n",
        "      # display(TF.to_pil_image(tf(image)[0]))\n",
        "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1).cpu())\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "model_url = \"/content/stylegan3-t-afhqv2-512x512.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths = \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/giggling.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ]
    }
  ]
}