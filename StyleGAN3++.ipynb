{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN3++.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzIduAHwCMUDK1JT4UCQyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjjuurang/CLIP/blob/main/StyleGAN3%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install --upgrade https://download.pytorch.org/whl/nightly/cu111/torch-1.11.0.dev20211012%2Bcu111-cp37-cp37m-linux_x86_64.whl https://download.pytorch.org/whl/nightly/cu111/torchvision-0.12.0.dev20211012%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "!git clone https://github.com/NVlabs/stylegan3\n",
        "!git clone https://github.com/openai/CLIP\n",
        "!pip install -e ./CLIP\n",
        "!pip install einops ninja\n",
        "\n",
        "import sys\n",
        "sys.path.append('./CLIP')\n",
        "sys.path.append('./stylegan3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMFvMqutlETj",
        "outputId": "79253117-f29a-4eae-8628-f797f5fe7e22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.9 MB/s eta 0:10:50tcmalloc: large alloc 1147494400 bytes == 0x3a08e000 @  0x7f6042ba2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.4 MB/s eta 0:11:35tcmalloc: large alloc 1434370048 bytes == 0x7e6e4000 @  0x7f6042ba2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.3 MB/s eta 0:09:07tcmalloc: large alloc 1792966656 bytes == 0x3516000 @  0x7f6042ba2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.3 MB/s eta 0:04:38tcmalloc: large alloc 2241208320 bytes == 0x6e2fe000 @  0x7f6042ba2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041315328 bytes == 0xf3c60000 @  0x7f6042ba11e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2551644160 bytes == 0x1e1ba4000 @  0x7f6042ba2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 8.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 100.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1+cu111) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1+cu111 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.1+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.1+cu111 torchvision-0.10.1+cu111\n",
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Total 207 (delta 0), reused 0 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (207/207), 4.16 MiB | 4.48 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n",
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Total 222 (delta 0), reused 0 (delta 0), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (222/222), 8.91 MiB | 5.56 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n",
            "Obtaining file:///content/CLIP\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.9.1+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.10.1+cu111)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Installing collected packages: ftfy, clip\n",
            "  Running setup.py develop for clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 55.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja, einops\n",
            "Successfully installed einops-0.4.1 ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AzzsYx1mGTF",
        "outputId": "5b804373-854a-44d8-a3a3-91325daf3841"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 43.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 44.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 37.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 42.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.1+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://archive.org/download/lhq-256-stylegan3-t-25Mimg/lhq-256-stylegan3-t-25Mimg.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF4IOutu1BCz",
        "outputId": "73644f11-e11e-41a4-ca85-4212013b5367"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 12:14:34--  https://archive.org/download/lhq-256-stylegan3-t-25Mimg/lhq-256-stylegan3-t-25Mimg.pkl\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia802208.us.archive.org/35/items/lhq-256-stylegan3-t-25Mimg/lhq-256-stylegan3-t-25Mimg.pkl [following]\n",
            "--2022-05-23 12:14:35--  https://ia802208.us.archive.org/35/items/lhq-256-stylegan3-t-25Mimg/lhq-256-stylegan3-t-25Mimg.pkl\n",
            "Resolving ia802208.us.archive.org (ia802208.us.archive.org)... 207.241.228.78\n",
            "Connecting to ia802208.us.archive.org (ia802208.us.archive.org)|207.241.228.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 343475703 (328M) [application/octet-stream]\n",
            "Saving to: ‘lhq-256-stylegan3-t-25Mimg.pkl’\n",
            "\n",
            "lhq-256-stylegan3-t 100%[===================>] 327.56M   208KB/s    in 16m 30s \n",
            "\n",
            "2022-05-23 12:31:06 (339 KB/s) - ‘lhq-256-stylegan3-t-25Mimg.pkl’ saved [343475703/343475703]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhqu-1024x1024.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wok9mbsH1OOU",
        "outputId": "e8622f2e-5886-474d-a3d6-c7a978e68407"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 12:31:10--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhqu-1024x1024.pkl\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 54.67.57.139, 52.53.133.234\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|54.67.57.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-ffhqu-1024x1024.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-t-ffhqu-1024x1024.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHQaCXVzLXdlc3QtMSJIMEYCIQDq25WvwdEKkrtVikmngkqWRGlcb5rL1ox6ScKsKU60LgIhANrP6Sj9h7ksYycQV%2BCc%2FpHRB%2Bs62NSwE6knrOkFU5JPKtIECF0QBBoMNzg5MzYzMTM1MDI3Igzpqje9aW0v24Syz0UqrwTe0WaDX3p5nud3ADMxEVKW1SDVChFjYFFFFUdJViR4%2FfiQPE14XivS32E59ah4Lu9fbpyVuLk2VkFJAvH9rrKzwfYDq9wrnhaxHuPh9HHv7Uw%2F0CXv38NNEo4DJAFLVIxGVrpr3FPWAIXIPjYDx1ROATDSv5tfeanDHtwZ6oSpeXWH9kWYiKfbL1PynMVrAJjj8mlAS3tI3oruUrcvfO3nx1oDni%2FMeDWEx6DI%2FdCoBOEzbZMgPnWUIT0CV8j9DFpbKv%2Fobzi%2B09PNCgp%2Be7bNpolg%2FJpdscZA7LvMD6BugzTiSdVLaAUckaYnEe4izSWW1NRtNFMmMQYr2nOg89qHJ9CA8XF49th6JmQS4McTCSrU0Rc6WlVA5PSvuMdCBc%2FDeHtu34FL6%2F%2B2Av8997t73RkJtO%2Ft85gnXy3H%2FdfQMa3kofgVuew3aXql9co6Lb5iG2IPlbFYvRT7Jv5hL9qKpmfJlyo%2B5If3JxOlL1LT8g1fHnld4U%2FUj0zj2KT0WsYuJDxgnwfcE%2BepbUWuOttGohsedOHvSSgcsOEjcGVevt8aiKv8xHSNn8VWxXFitsHGHe8nQD7RUEY1G0Z9QfaUrmeOwUqygagWycmt194qnRLZKfzahJyOotgZJpR9e6gI%2B%2FPeN9m3YQnqlKYteDTY1uTxCSaz1zCiiOnFl84B8mlIPYyaP40rhRNGfCPQgOrju3eYVDjExnOsr7nKL2TjDv5ibk7bz7j9hqTg%2F8GvMOz2rZQGOqgBgTNKcvP7qco9R8kkvoywtdxmv%2B%2Bh5sgC75HO8Iunj5ATF9q6h0Bva5HVZG4en33fA8sDfV3T1NFJT0WMPXW2rFVUhHA13Zf65H4znAqMQpNgiglML0KsVrbj3cQkHQ8KajJCoRLAqRbaHYwxw1SRZPwcTNBKD%2FehY6lkFQj6zuNUI7Tz9wBQasx2pR3eZQuY3kKuclxdGGoT0oaGqz5pO9UH46RKT7bl&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220523T123112Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZVQV4XGOC%2F20220523%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=3e88d29b99932d807851d02f9c7aae54fa57685e0711ca73ae3bea0661adaa8c [following]\n",
            "--2022-05-23 12:31:12--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-ffhqu-1024x1024.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-t-ffhqu-1024x1024.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHQaCXVzLXdlc3QtMSJIMEYCIQDq25WvwdEKkrtVikmngkqWRGlcb5rL1ox6ScKsKU60LgIhANrP6Sj9h7ksYycQV%2BCc%2FpHRB%2Bs62NSwE6knrOkFU5JPKtIECF0QBBoMNzg5MzYzMTM1MDI3Igzpqje9aW0v24Syz0UqrwTe0WaDX3p5nud3ADMxEVKW1SDVChFjYFFFFUdJViR4%2FfiQPE14XivS32E59ah4Lu9fbpyVuLk2VkFJAvH9rrKzwfYDq9wrnhaxHuPh9HHv7Uw%2F0CXv38NNEo4DJAFLVIxGVrpr3FPWAIXIPjYDx1ROATDSv5tfeanDHtwZ6oSpeXWH9kWYiKfbL1PynMVrAJjj8mlAS3tI3oruUrcvfO3nx1oDni%2FMeDWEx6DI%2FdCoBOEzbZMgPnWUIT0CV8j9DFpbKv%2Fobzi%2B09PNCgp%2Be7bNpolg%2FJpdscZA7LvMD6BugzTiSdVLaAUckaYnEe4izSWW1NRtNFMmMQYr2nOg89qHJ9CA8XF49th6JmQS4McTCSrU0Rc6WlVA5PSvuMdCBc%2FDeHtu34FL6%2F%2B2Av8997t73RkJtO%2Ft85gnXy3H%2FdfQMa3kofgVuew3aXql9co6Lb5iG2IPlbFYvRT7Jv5hL9qKpmfJlyo%2B5If3JxOlL1LT8g1fHnld4U%2FUj0zj2KT0WsYuJDxgnwfcE%2BepbUWuOttGohsedOHvSSgcsOEjcGVevt8aiKv8xHSNn8VWxXFitsHGHe8nQD7RUEY1G0Z9QfaUrmeOwUqygagWycmt194qnRLZKfzahJyOotgZJpR9e6gI%2B%2FPeN9m3YQnqlKYteDTY1uTxCSaz1zCiiOnFl84B8mlIPYyaP40rhRNGfCPQgOrju3eYVDjExnOsr7nKL2TjDv5ibk7bz7j9hqTg%2F8GvMOz2rZQGOqgBgTNKcvP7qco9R8kkvoywtdxmv%2B%2Bh5sgC75HO8Iunj5ATF9q6h0Bva5HVZG4en33fA8sDfV3T1NFJT0WMPXW2rFVUhHA13Zf65H4znAqMQpNgiglML0KsVrbj3cQkHQ8KajJCoRLAqRbaHYwxw1SRZPwcTNBKD%2FehY6lkFQj6zuNUI7Tz9wBQasx2pR3eZQuY3kKuclxdGGoT0oaGqz5pO9UH46RKT7bl&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220523T123112Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZVQV4XGOC%2F20220523%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=3e88d29b99932d807851d02f9c7aae54fa57685e0711ca73ae3bea0661adaa8c\n",
            "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.216.73\n",
            "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.216.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 294775122 (281M) [application/octet-stream]\n",
            "Saving to: ‘stylegan3-t-ffhqu-1024x1024.pkl’\n",
            "\n",
            "stylegan3-t-ffhqu-1 100%[===================>] 281.12M  17.1MB/s    in 17s     \n",
            "\n",
            "2022-05-23 12:31:31 (16.2 MB/s) - ‘stylegan3-t-ffhqu-1024x1024.pkl’ saved [294775122/294775122]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-afhqv2-512x512.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuKcvDLZoq_u",
        "outputId": "8068eeb2-13d9-4944-e0fb-432959f7a37b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 06:38:44--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-afhqv2-512x512.pkl\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 35.160.122.182, 54.214.150.211\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|35.160.122.182|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-afhqv2-512x512.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-t-afhqv2-512x512.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEG4aCXVzLXdlc3QtMiJGMEQCIAhJK%2FgRu0RTn%2BaEnoewj77uNliEsxCBc9mjPCif%2Bk50AiAHTf9qApt9XUsI441vH5cvSFqj97Nlwc1FDuvtw14HXSrSBAhXEAQaDDc4OTM2MzEzNTAyNyIMsfQluG9vJWnPKXohKq8EhINZHPsR0Ej2584a9e7HSji6xqkCLLT131RLsQn9nUh1xkj8BPUyXIpXEkixZjC6HAcDMP4f%2FjJSVlEW9S8opxuCpAds5x6xozk2yh2yHrysLQ4jlI7Y5Id4fHW5k6Q0bDFfFGcdopgS6C2cNPxGNGS81fzOR%2F4w75TKVre%2FY2hoAMLbqLQohdH2Exky7LR8yeLp07bmQ4TZCiQQIjyyxSXGCcqjer6dqqvDmrdNOnnyhRJSGhcykaO9KfRWcvYUMceNwDOEfl4H6pj5VWIC77UtxMRe%2FMbNBUoj8NzrGdoGzivJZnsmKDRVFDkwUnunzxINju3t8Xrj%2BNpcyFKkTwaR%2F74JcvOMW3p17UnibLEp6DyEVCqx3V8THpZaSs%2Bk%2FXlrmBCF6JT0OGZLSRv9QXoqzGJjSZB8GQEUEn2hpd%2F78njWN%2FfZ%2BMafnKDm7YySYvOvBqxDTRir7O5L4r5rfyOEhd72uHmSccXGIQaZX8YD0I0HVQXFME9M7LIyLOr%2Fgbpwoq697xzyTwemplqqXKxTQdTqPIJMcj5qjo0XMDaqyjXJ8UdlhyHr5vnPm2%2FyuwpPZtlpg0urYTRP2JGhj6GE0sUREYo70qVS3TdX4UVHUIkLFPxEdBAEYGFf%2BiyBtcSXTAD%2Bi7YEgY71Wcnqj5609dHFR8Ykruv0NVQyI03vCIr00%2FY8L3B%2Fh7ubNMNhYRSd0gtK%2B2TG4mkjQfPB1v056EK7RsbZmF76P7bcFTC%2BxqyUBjqqAaD%2BxBOsa9VPHq%2FsohPuKEMp2DV1IEnGutb34Cc01tkv%2FNGVG5y9MaH0013TVemWe1pPaqZ4zmkfrgONWuc66QNSo1DZY2Sihtt%2FXcRpdBK8yz4%2FtPRCHvmrAAlc27SjnuHTOXyujMQl01LpCfqq%2B1Nm3yJ0Wpzja2I9JsKxr%2FAnMjWMMT%2FLXD6%2BBmOehd8PhvO1dRoLT0SBaNBJtrarojzt3rHYO0YXbz8I&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220523T063846Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZ56BGF34O%2F20220523%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=5db8ca49dd3b600ba4044caaac02865d71a419e3e585b44d5a03c8bc03e4693d [following]\n",
            "--2022-05-23 06:38:46--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-afhqv2-512x512.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan3-t-afhqv2-512x512.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEG4aCXVzLXdlc3QtMiJGMEQCIAhJK%2FgRu0RTn%2BaEnoewj77uNliEsxCBc9mjPCif%2Bk50AiAHTf9qApt9XUsI441vH5cvSFqj97Nlwc1FDuvtw14HXSrSBAhXEAQaDDc4OTM2MzEzNTAyNyIMsfQluG9vJWnPKXohKq8EhINZHPsR0Ej2584a9e7HSji6xqkCLLT131RLsQn9nUh1xkj8BPUyXIpXEkixZjC6HAcDMP4f%2FjJSVlEW9S8opxuCpAds5x6xozk2yh2yHrysLQ4jlI7Y5Id4fHW5k6Q0bDFfFGcdopgS6C2cNPxGNGS81fzOR%2F4w75TKVre%2FY2hoAMLbqLQohdH2Exky7LR8yeLp07bmQ4TZCiQQIjyyxSXGCcqjer6dqqvDmrdNOnnyhRJSGhcykaO9KfRWcvYUMceNwDOEfl4H6pj5VWIC77UtxMRe%2FMbNBUoj8NzrGdoGzivJZnsmKDRVFDkwUnunzxINju3t8Xrj%2BNpcyFKkTwaR%2F74JcvOMW3p17UnibLEp6DyEVCqx3V8THpZaSs%2Bk%2FXlrmBCF6JT0OGZLSRv9QXoqzGJjSZB8GQEUEn2hpd%2F78njWN%2FfZ%2BMafnKDm7YySYvOvBqxDTRir7O5L4r5rfyOEhd72uHmSccXGIQaZX8YD0I0HVQXFME9M7LIyLOr%2Fgbpwoq697xzyTwemplqqXKxTQdTqPIJMcj5qjo0XMDaqyjXJ8UdlhyHr5vnPm2%2FyuwpPZtlpg0urYTRP2JGhj6GE0sUREYo70qVS3TdX4UVHUIkLFPxEdBAEYGFf%2BiyBtcSXTAD%2Bi7YEgY71Wcnqj5609dHFR8Ykruv0NVQyI03vCIr00%2FY8L3B%2Fh7ubNMNhYRSd0gtK%2B2TG4mkjQfPB1v056EK7RsbZmF76P7bcFTC%2BxqyUBjqqAaD%2BxBOsa9VPHq%2FsohPuKEMp2DV1IEnGutb34Cc01tkv%2FNGVG5y9MaH0013TVemWe1pPaqZ4zmkfrgONWuc66QNSo1DZY2Sihtt%2FXcRpdBK8yz4%2FtPRCHvmrAAlc27SjnuHTOXyujMQl01LpCfqq%2B1Nm3yJ0Wpzja2I9JsKxr%2FAnMjWMMT%2FLXD6%2BBmOehd8PhvO1dRoLT0SBaNBJtrarojzt3rHYO0YXbz8I&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220523T063846Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3599&X-Amz-Credential=ASIA3PSNVSIZ56BGF34O%2F20220523%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=5db8ca49dd3b600ba4044caaac02865d71a419e3e585b44d5a03c8bc03e4693d\n",
            "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.176.57\n",
            "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.176.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 315163814 (301M) [application/octet-stream]\n",
            "Saving to: ‘stylegan3-t-afhqv2-512x512.pkl’\n",
            "\n",
            "stylegan3-t-afhqv2- 100%[===================>] 300.56M  17.5MB/s    in 18s     \n",
            "\n",
            "2022-05-23 06:39:06 (16.3 MB/s) - ‘stylegan3-t-afhqv2-512x512.pkl’ saved [315163814/315163814]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2dST3fnhwd-",
        "outputId": "9f91d684-2f90-407b-d3c6-9cf4e88bd65e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n",
            "  0%|          | 1/200 [00:00<01:19,  2.50it/s, loss=0.115, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0/200 | Current loss: 0.11514697223901749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [00:03<01:16,  2.48it/s, loss=0.117, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 9/200 | Current loss: 0.11658503115177155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [00:04<01:15,  2.50it/s, loss=0.114, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 10/200 | Current loss: 0.11420343816280365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 20/200 [00:07<01:13,  2.46it/s, loss=0.113, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 19/200 | Current loss: 0.11251052469015121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:08<01:12,  2.48it/s, loss=0.111, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 20/200 | Current loss: 0.11145616322755814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 30/200 [00:11<01:09,  2.45it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 29/200 | Current loss: 0.11157096177339554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [00:11<01:08,  2.47it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 30/200 | Current loss: 0.1117543876171112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [00:15<01:06,  2.42it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 39/200 | Current loss: 0.11184442043304443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [00:15<01:04,  2.45it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 40/200 | Current loss: 0.11197835206985474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:19<01:01,  2.42it/s, loss=0.111, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 49/200 | Current loss: 0.11132191866636276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [00:19<01:01,  2.44it/s, loss=0.111, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 50/200 | Current loss: 0.11109700053930283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 60/200 [00:23<00:58,  2.41it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 59/200 | Current loss: 0.1121426671743393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [00:23<00:57,  2.43it/s, loss=0.113, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 60/200 | Current loss: 0.1125423014163971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:27<00:54,  2.39it/s, loss=0.112, q_magnitude=0.666]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 69/200 | Current loss: 0.11244366317987442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [00:27<00:53,  2.41it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 70/200 | Current loss: 0.11241307854652405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [00:31<00:50,  2.36it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 79/200 | Current loss: 0.11188983172178268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [00:31<00:49,  2.38it/s, loss=0.111, q_magnitude=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 80/200 | Current loss: 0.11142916232347488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [00:35<00:46,  2.36it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 89/200 | Current loss: 0.11193294823169708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [00:35<00:45,  2.38it/s, loss=0.112, q_magnitude=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 90/200 | Current loss: 0.11157742887735367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [00:39<00:42,  2.33it/s, loss=0.113, q_magnitude=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 99/200 | Current loss: 0.11331219971179962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [00:39<00:41,  2.36it/s, loss=0.114, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 100/200 | Current loss: 0.11378669738769531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 110/200 [00:43<00:38,  2.36it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 109/200 | Current loss: 0.11183404922485352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [00:43<00:37,  2.39it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 110/200 | Current loss: 0.11154626309871674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 120/200 [00:47<00:33,  2.37it/s, loss=0.111, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 119/200 | Current loss: 0.11057412624359131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [00:47<00:32,  2.40it/s, loss=0.111, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 120/200 | Current loss: 0.11107035726308823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 130/200 [00:51<00:29,  2.38it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 129/200 | Current loss: 0.11128796637058258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [00:51<00:28,  2.41it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 130/200 | Current loss: 0.1121176928281784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 140/200 [00:55<00:24,  2.40it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 139/200 | Current loss: 0.11107420176267624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [00:55<00:24,  2.43it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 140/200 | Current loss: 0.11161737889051437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [00:59<00:20,  2.42it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 149/200 | Current loss: 0.11095880717039108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [00:59<00:20,  2.44it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 150/200 | Current loss: 0.11124267429113388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [01:03<00:16,  2.42it/s, loss=0.111, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 159/200 | Current loss: 0.11097431927919388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [01:03<00:15,  2.44it/s, loss=0.112, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 160/200 | Current loss: 0.11153680831193924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 170/200 [01:06<00:12,  2.44it/s, loss=0.111, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 169/200 | Current loss: 0.11120787262916565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [01:07<00:11,  2.47it/s, loss=0.111, q_magnitude=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 170/200 | Current loss: 0.11133819073438644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 180/200 [01:10<00:08,  2.43it/s, loss=0.112, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 179/200 | Current loss: 0.11202046275138855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [01:11<00:07,  2.45it/s, loss=0.113, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 180/200 | Current loss: 0.11255677789449692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [01:14<00:04,  2.43it/s, loss=0.116, q_magnitude=0.672]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 189/200 | Current loss: 0.11608592420816422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [01:15<00:03,  2.46it/s, loss=0.115, q_magnitude=0.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 190/200 | Current loss: 0.11472124606370926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:18<00:00,  2.55it/s, loss=0.112, q_magnitude=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 199/200 | Current loss: 0.1119939461350441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import librosa\n",
        "import cv2\n",
        "\n",
        "def make_transform(translate, angle):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "    \n",
        "class AudioEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AudioEncoder, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(1, 3, (3, 3))\n",
        "        self.feature_extractor = timm.create_model(\"resnet18\", num_classes=512, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/32\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      # return norm1(self.model.encode_image(self.normalize(image)))\n",
        "      return norm1(self.model.encode_image(image))\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "  ])\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def run(timestring):\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  # Init\n",
        "  # Sample 32 inits and choose the one closest to prompt\n",
        "\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(8):\n",
        "      q = (G.mapping(torch.randn([4,G.mapping.z_dim], device=device), None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
        "      images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).requires_grad_()\n",
        "\n",
        "  w_init = (q * w_stds + G.mapping.w_avg).detach().clone()\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  opt = torch.optim.AdamW([q], lr=0.03, betas=(0.0,0.999))\n",
        "  loop = tqdm(range(steps))\n",
        "  for i in loop:\n",
        "    opt.zero_grad()\n",
        "    w = q * w_stds + G.mapping.w_avg\n",
        "    image = G.synthesis(w , noise_mode='const')\n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = 0.1 *  prompts_dist_loss(embed, targets, spherical_dist_loss).mean() + ((w - w_init) ** 2).mean()\n",
        "    # loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    q_ema = q_ema * 0.9 + q * 0.1\n",
        "\n",
        "    final_code = q_ema * w_stds + G.mapping.w_avg\n",
        "    final_code[:,6:,:] = w_init[:,6:,:]\n",
        "    image = G.synthesis(final_code, noise_mode='const')\n",
        "\n",
        "    if i % 10 == 9 or i % 10 == 0:\n",
        "      # display(TF.to_pil_image(tf(image)[0]))\n",
        "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1).cpu())\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "model_url = \"/content/stylegan3-t-afhqv2-512x512.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths = \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/giggling.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import librosa\n",
        "import cv2\n",
        "\n",
        "def make_transform(translate, angle):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "    \n",
        "class AudioEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AudioEncoder, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(1, 3, (3, 3))\n",
        "        self.feature_extractor = timm.create_model(\"resnet18\", num_classes=512, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/32\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      # return norm1(self.model.encode_image(self.normalize(image)))\n",
        "      return norm1(self.model.encode_image(image))\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "  ])\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def run(timestring):\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  # Init\n",
        "  # Sample 32 inits and choose the one closest to prompt\n",
        "\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(8):\n",
        "      q = (G.mapping(torch.randn([4,G.mapping.z_dim], device=device), None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
        "      images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).requires_grad_()\n",
        "\n",
        "  w_init = (q * w_stds + G.mapping.w_avg).detach().clone()\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  opt = torch.optim.AdamW([q], lr=0.03, betas=(0.0,0.999))\n",
        "  loop = tqdm(range(steps))\n",
        "  for i in loop:\n",
        "    opt.zero_grad()\n",
        "    w = q * w_stds + G.mapping.w_avg\n",
        "    image = G.synthesis(w , noise_mode='const')\n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = 0.1 *  prompts_dist_loss(embed, targets, spherical_dist_loss).mean() + ((w - w_init) ** 2).mean()\n",
        "    # loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    q_ema = q_ema * 0.9 + q * 0.1\n",
        "\n",
        "    final_code = q_ema * w_stds + G.mapping.w_avg\n",
        "    final_code[:,6:,:] = w_init[:,6:,:]\n",
        "    image = G.synthesis(final_code, noise_mode='const')\n",
        "\n",
        "    if i % 10 == 9 or i % 10 == 0:\n",
        "      # display(TF.to_pil_image(tf(image)[0]))\n",
        "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1).cpu())\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "model_url = \"/content/lhq-256-stylegan3-t-25Mimg.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths = \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/explosion.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukXCdDT51sNy",
        "outputId": "d51bcb37-41bc-429d-d5b5-192d94ff239b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/200 [00:00<01:13,  2.71it/s, loss=0.109, q_magnitude=0.742]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0/200 | Current loss: 0.1087099090218544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [00:02<00:50,  3.77it/s, loss=0.106, q_magnitude=0.743]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 9/200 | Current loss: 0.10550844669342041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [00:02<00:49,  3.79it/s, loss=0.104, q_magnitude=0.744]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 10/200 | Current loss: 0.10375003516674042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 20/200 [00:05<00:47,  3.77it/s, loss=0.101, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 19/200 | Current loss: 0.10085055232048035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:05<00:47,  3.79it/s, loss=0.101, q_magnitude=0.745]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 20/200 | Current loss: 0.10145542025566101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 30/200 [00:07<00:45,  3.75it/s, loss=0.107, q_magnitude=0.749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 29/200 | Current loss: 0.10705044865608215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [00:08<00:44,  3.77it/s, loss=0.102, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 30/200 | Current loss: 0.10170746594667435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [00:10<00:42,  3.74it/s, loss=0.105, q_magnitude=0.752]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 39/200 | Current loss: 0.10540564358234406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [00:10<00:42,  3.75it/s, loss=0.105, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 40/200 | Current loss: 0.10500264167785645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:12<00:40,  3.72it/s, loss=0.0951, q_magnitude=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 49/200 | Current loss: 0.09508431702852249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [00:13<00:39,  3.73it/s, loss=0.0941, q_magnitude=0.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 50/200 | Current loss: 0.09408392757177353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 60/200 [00:15<00:37,  3.71it/s, loss=0.101, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 59/200 | Current loss: 0.1014159619808197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [00:15<00:37,  3.74it/s, loss=0.0975, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 60/200 | Current loss: 0.09748882055282593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:18<00:35,  3.71it/s, loss=0.107, q_magnitude=0.756]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 69/200 | Current loss: 0.1070968508720398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [00:18<00:34,  3.71it/s, loss=0.123, q_magnitude=0.758]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 70/200 | Current loss: 0.12274368107318878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [00:20<00:32,  3.68it/s, loss=0.0965, q_magnitude=0.749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 79/200 | Current loss: 0.09647274017333984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [00:20<00:32,  3.70it/s, loss=0.0956, q_magnitude=0.749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 80/200 | Current loss: 0.0956030860543251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [00:23<00:29,  3.69it/s, loss=0.0944, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 89/200 | Current loss: 0.09436219930648804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [00:23<00:29,  3.72it/s, loss=0.0927, q_magnitude=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 90/200 | Current loss: 0.09272222220897675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [00:25<00:27,  3.68it/s, loss=0.0934, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 99/200 | Current loss: 0.09343009442090988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [00:26<00:26,  3.70it/s, loss=0.0927, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 100/200 | Current loss: 0.0927022397518158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 110/200 [00:28<00:24,  3.66it/s, loss=0.0966, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 109/200 | Current loss: 0.09656444191932678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [00:28<00:24,  3.70it/s, loss=0.0936, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 110/200 | Current loss: 0.09358526021242142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 120/200 [00:31<00:21,  3.65it/s, loss=0.0919, q_magnitude=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 119/200 | Current loss: 0.09191665053367615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [00:31<00:21,  3.68it/s, loss=0.09, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 120/200 | Current loss: 0.08998016268014908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 130/200 [00:33<00:19,  3.65it/s, loss=0.101, q_magnitude=0.753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 129/200 | Current loss: 0.1006699800491333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [00:34<00:18,  3.68it/s, loss=0.0974, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 130/200 | Current loss: 0.09736203402280807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 140/200 [00:36<00:16,  3.65it/s, loss=0.0937, q_magnitude=0.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 139/200 | Current loss: 0.09373883903026581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [00:36<00:16,  3.68it/s, loss=0.0927, q_magnitude=0.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 140/200 | Current loss: 0.09272082149982452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [00:39<00:13,  3.63it/s, loss=0.0989, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 149/200 | Current loss: 0.0988953486084938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [00:39<00:13,  3.66it/s, loss=0.0942, q_magnitude=0.749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 150/200 | Current loss: 0.09418006241321564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [00:41<00:11,  3.63it/s, loss=0.0938, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 159/200 | Current loss: 0.09384176880121231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [00:41<00:10,  3.64it/s, loss=0.0986, q_magnitude=0.751]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 160/200 | Current loss: 0.0985763669013977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 170/200 [00:44<00:08,  3.62it/s, loss=0.0906, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 169/200 | Current loss: 0.09061897546052933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [00:44<00:07,  3.64it/s, loss=0.0905, q_magnitude=0.746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 170/200 | Current loss: 0.09048780053853989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 180/200 [00:46<00:05,  3.63it/s, loss=0.0959, q_magnitude=0.749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 179/200 | Current loss: 0.09587077796459198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [00:47<00:05,  3.65it/s, loss=0.102, q_magnitude=0.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 180/200 | Current loss: 0.10220624506473541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [00:49<00:02,  3.61it/s, loss=0.103, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 189/200 | Current loss: 0.10312704741954803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [00:49<00:02,  3.64it/s, loss=0.107, q_magnitude=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 190/200 | Current loss: 0.10689238458871841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:52<00:00,  3.82it/s, loss=0.0989, q_magnitude=0.748]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 199/200 | Current loss: 0.09885771572589874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_url = \"/content/stylegan3-t-ffhqu-1024x1024.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths = \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/giggling.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DJAIFhv1tZV",
        "outputId": "07b3ead7-25ab-4280-dc52-af7e93fb62d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/200 [00:00<01:52,  1.78it/s, loss=0.112, q_magnitude=0.674]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0/200 | Current loss: 0.11189337819814682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [00:05<01:44,  1.82it/s, loss=0.109, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 9/200 | Current loss: 0.10948608815670013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/200 [00:05<01:45,  1.80it/s, loss=0.108, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 10/200 | Current loss: 0.10834617167711258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 20/200 [00:10<01:39,  1.81it/s, loss=0.106, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 19/200 | Current loss: 0.10585017502307892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 21/200 [00:10<01:39,  1.81it/s, loss=0.107, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 20/200 | Current loss: 0.10655154287815094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 30/200 [00:15<01:34,  1.80it/s, loss=0.106, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 29/200 | Current loss: 0.10598714649677277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 31/200 [00:16<01:34,  1.79it/s, loss=0.104, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 30/200 | Current loss: 0.10417953878641129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [00:20<01:29,  1.79it/s, loss=0.104, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 39/200 | Current loss: 0.10442103445529938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 41/200 [00:21<01:28,  1.79it/s, loss=0.103, q_magnitude=0.681]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 40/200 | Current loss: 0.102569580078125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:25<01:24,  1.77it/s, loss=0.102, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 49/200 | Current loss: 0.10192380100488663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 51/200 [00:26<01:23,  1.77it/s, loss=0.101, q_magnitude=0.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 50/200 | Current loss: 0.10091647505760193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 60/200 [00:31<01:18,  1.77it/s, loss=0.103, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 59/200 | Current loss: 0.10343747586011887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 61/200 [00:31<01:18,  1.77it/s, loss=0.106, q_magnitude=0.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 60/200 | Current loss: 0.10611957311630249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:36<01:13,  1.77it/s, loss=0.104, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 69/200 | Current loss: 0.10397819429636002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 71/200 [00:37<01:13,  1.76it/s, loss=0.103, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 70/200 | Current loss: 0.10264446586370468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 80/200 [00:41<01:07,  1.78it/s, loss=0.103, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 79/200 | Current loss: 0.10292495787143707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 81/200 [00:42<01:06,  1.78it/s, loss=0.105, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 80/200 | Current loss: 0.10459758341312408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [00:46<01:01,  1.79it/s, loss=0.105, q_magnitude=0.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 89/200 | Current loss: 0.10508451610803604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 91/200 [00:47<01:01,  1.78it/s, loss=0.106, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 90/200 | Current loss: 0.10619454830884933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [00:52<00:55,  1.80it/s, loss=0.107, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 99/200 | Current loss: 0.10696861147880554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [00:52<00:55,  1.79it/s, loss=0.105, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 100/200 | Current loss: 0.10544977337121964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 110/200 [00:57<00:49,  1.81it/s, loss=0.106, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 109/200 | Current loss: 0.10552824288606644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 111/200 [00:57<00:49,  1.80it/s, loss=0.105, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 110/200 | Current loss: 0.10494356602430344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 120/200 [01:02<00:44,  1.80it/s, loss=0.104, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 119/200 | Current loss: 0.10388611257076263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 121/200 [01:03<00:43,  1.80it/s, loss=0.105, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 120/200 | Current loss: 0.10494060814380646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 130/200 [01:07<00:38,  1.82it/s, loss=0.103, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 129/200 | Current loss: 0.10276241600513458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 131/200 [01:08<00:38,  1.81it/s, loss=0.106, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 130/200 | Current loss: 0.10613658279180527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 140/200 [01:12<00:32,  1.82it/s, loss=0.105, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 139/200 | Current loss: 0.10533924400806427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 141/200 [01:13<00:32,  1.82it/s, loss=0.108, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 140/200 | Current loss: 0.10784366726875305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [01:17<00:27,  1.82it/s, loss=0.105, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 149/200 | Current loss: 0.10466790944337845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 151/200 [01:18<00:27,  1.81it/s, loss=0.105, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 150/200 | Current loss: 0.10545212030410767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 160/200 [01:23<00:21,  1.82it/s, loss=0.104, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 159/200 | Current loss: 0.10420394688844681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 161/200 [01:23<00:21,  1.81it/s, loss=0.103, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 160/200 | Current loss: 0.1028452068567276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 170/200 [01:28<00:16,  1.82it/s, loss=0.104, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 169/200 | Current loss: 0.1039862334728241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 171/200 [01:28<00:16,  1.81it/s, loss=0.103, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 170/200 | Current loss: 0.10255128890275955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 180/200 [01:33<00:11,  1.81it/s, loss=0.104, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 179/200 | Current loss: 0.10386236011981964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 181/200 [01:33<00:10,  1.81it/s, loss=0.104, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 180/200 | Current loss: 0.10361884534358978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [01:38<00:05,  1.81it/s, loss=0.106, q_magnitude=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 189/200 | Current loss: 0.10585089027881622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 191/200 [01:39<00:04,  1.81it/s, loss=0.107, q_magnitude=0.677]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 190/200 | Current loss: 0.10718248039484024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:43<00:00,  1.93it/s, loss=0.105, q_magnitude=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 199/200 | Current loss: 0.10461181402206421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from einops import rearrange\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import librosa\n",
        "import cv2\n",
        "\n",
        "def make_transform(translate, angle):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "    \n",
        "class AudioEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AudioEncoder, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(1, 3, (3, 3))\n",
        "        self.feature_extractor = timm.create_model(\"resnet18\", num_classes=512, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/32\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      # return norm1(self.model.encode_image(self.normalize(image)))\n",
        "      return norm1(self.model.encode_image(image))\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "  ])\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def run(timestring):\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  # Init\n",
        "  # Sample 32 inits and choose the one closest to prompt\n",
        "\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(8):\n",
        "      q = (G.mapping(torch.randn([4,G.mapping.z_dim], device=device), None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
        "      images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).requires_grad_()\n",
        "\n",
        "  w_init = (q * w_stds + G.mapping.w_avg).detach().clone()\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  opt = torch.optim.AdamW([q], lr=0.03, betas=(0.0,0.999))\n",
        "  loop = tqdm(range(steps))\n",
        "  for i in loop:\n",
        "    opt.zero_grad()\n",
        "    w = q * w_stds + G.mapping.w_avg\n",
        "    image = G.synthesis(w , noise_mode='const')\n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = 0.1 *  prompts_dist_loss(embed, targets, spherical_dist_loss).mean() + ((w - w_init) ** 2).mean()\n",
        "    # loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    q_ema = q_ema * 0.9 + q * 0.1\n",
        "\n",
        "    final_code = q_ema * w_stds + G.mapping.w_avg\n",
        "    final_code[:,6:,:] = w_init[:,6:,:]\n",
        "    image = G.synthesis(final_code, noise_mode='const')\n",
        "\n",
        "    if i % 10 == 9 or i % 10 == 0:\n",
        "      # display(TF.to_pil_image(tf(image)[0]))\n",
        "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1).cpu())\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "model_url = \"/content/stylegan3-t-afhqv2-512x512.pkl\"\n",
        "\n",
        "with open(model_url, 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "zs = torch.randn([100000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "m = make_transform([0,0], 0)\n",
        "m = np.linalg.inv(m)\n",
        "G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "# audio_paths = \"./audio/sweet-kitty-meow.wav\"\n",
        "#audio_paths = \"./audio/dog-sad.wav\"\n",
        "audio_paths = \"/content/giggling.wav\"\n",
        "steps = 200\n",
        "seed = 14 + 22\n",
        "#seed = 22\n",
        "\n",
        "audio_paths = [frase.strip() for frase in audio_paths.split(\"|\") if frase]\n",
        "\n",
        "clip_model = CLIP()\n",
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.load_state_dict(copyStateDict(torch.load(\"/content/resnet18.pth\", map_location=device)))\n",
        "audio_encoder = audio_encoder.to(device)\n",
        "audio_encoder.eval()\n",
        "\n",
        "targets = []\n",
        "n_mels = 128\n",
        "time_length = 864\n",
        "resize_resolution = 512\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    audio_inputs = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    audio_inputs = librosa.power_to_db(audio_inputs, ref=np.max) / 80.0 + 1\n",
        "\n",
        "    zero = np.zeros((n_mels, time_length))\n",
        "    h, w = audio_inputs.shape\n",
        "    if w >= time_length:\n",
        "        j = (w - time_length) // 2\n",
        "        audio_inputs = audio_inputs[:,j:j+time_length]\n",
        "    else:\n",
        "        j = (time_length - w) // 2\n",
        "        zero[:,:w] = audio_inputs[:,:w]\n",
        "        audio_inputs = zero\n",
        "    \n",
        "    audio_inputs = cv2.resize(audio_inputs, (n_mels, resize_resolution))\n",
        "    audio_inputs = np.array([audio_inputs])\n",
        "    audio_inputs = torch.from_numpy(audio_inputs.reshape((1, 1, n_mels, resize_resolution))).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        audio_embedding = audio_encoder(audio_inputs)\n",
        "        audio_embedding = audio_embedding / audio_embedding.norm(dim=-1, keepdim=True)\n",
        "    targets.append(audio_embedding)\n",
        "\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "run(timestring)"
      ],
      "metadata": {
        "id": "Jk8eSvXq2R0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}